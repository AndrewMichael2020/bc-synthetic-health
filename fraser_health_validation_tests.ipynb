{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fraser Health Synthetic Data - Automated Testing & Clinical Validation Suite",
    "",
    "This notebook performs comprehensive validation of synthetic health data generated by the Fraser Health onboarding notebook.",
    "",
    "**Validation Categories:**",
    "1. **Statistical Demographic Parity** - Age and ethnicity distribution checks",
    "2. **Geographic Integrity & Referral Routing** - Location and distance validation",
    "3. **Clinical Timeline & FHIR R4 Compliance** - Encounter sequences and FHIR validation",
    "4. **Fraser Health Specific Stress Test** - Multi-seed consistency testing",
    "",
    "**Prerequisites:**",
    "- Run `fraser_health_onboarding.ipynb` first to generate synthetic data",
    "- Data expected in: `synthea/output/csv/` and `synthea/output/fhir/`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 0: Environment Setup & Imports"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0.1 Install Required Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages for validation\n",
    "import sys\n",
    "import subprocess\n",
    "\n",
    "print(\"Installing validation dependencies...\")\n",
    "!pip install -q pandas numpy matplotlib haversine fhir.resources scipy\n",
    "\n",
    "print(\"✓ Dependencies installed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0.2 Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# Core data processing and analysis libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "import os\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "\n# Date and time utilities\n",
    "from collections import Counter, defaultdict\n",
    "import warnings\n",
    "# Statistical utilities\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n# Suppress non-critical warnings for cleaner output\n",
    "# For geographic calculations\n",
    "try:\n",
    "\n# ========== GEOGRAPHIC CALCULATIONS ==========\n",
    "    from haversine import haversine, Unit\n",
    "# Haversine formula for calculating great-circle distances between two points on Earth\n",
    "    haversine_available = True\n",
    "# Used to detect unrealistic patient-provider distances (\"teleporting\" patients)\n",
    "except ImportError:\n",
    "    print(\"⚠ Haversine not available - installing...\")\n",
    "    !pip install haversine\n",
    "    from haversine import haversine, Unit\n",
    "    haversine_available = True\n",
    "\n",
    "# For FHIR validation\n",
    "\n# ========== FHIR VALIDATION ==========\n",
    "try:\n",
    "# FHIR (Fast Healthcare Interoperability Resources) R4 validation\n",
    "    from fhir.resources.bundle import Bundle\n",
    "# Ensures generated health data conforms to international healthcare data standards\n",
    "    from fhir.resources.patient import Patient\n",
    "    fhir_available = True\n",
    "except ImportError:\n",
    "    print(\"⚠ FHIR resources not available - some validation will be skipped\")\n",
    "    fhir_available = False\n",
    "\n",
    "print(\"✓ All libraries imported successfully\")\n",
    "print(f\"  - Haversine: {'✓' if haversine_available else '✗'}\")\n",
    "print(f\"  - FHIR Resources: {'✓' if fhir_available else '✗'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0.3 Configuration & Path Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========== CONFIGURATION ==========\n",
    "\n",
    "# Define paths to Synthea output directories\n",
    "# Paths\n",
    "SYNTHEA_DIR = Path(\"synthea\")\n",
    "OUTPUT_DIR = SYNTHEA_DIR / \"output\"\n",
    "CSV_DIR = OUTPUT_DIR / \"csv\"\n",
    "FHIR_DIR = OUTPUT_DIR / \"fhir\"\n",
    "CONFIG_DIR = Path(\"config\")\n",
    "\n# ========== DEMOGRAPHIC BASELINES ==========\n",
    "\n",
    "# Reference values from Statistics Canada 2021 Census for British Columbia\n",
    "# Expected BC demographics (BC 2021 Census approximations)\n",
    "# Used to validate that synthetic data matches real-world demographics\n",
    "# Source: Statistics Canada 2021 Census\n",
    "BC_MEDIAN_AGE_2021 = 42.8  # Years\n",
    "BC_AGE_TOLERANCE = 0.10  # 10% tolerance\n",
    "\n# ========== GEOGRAPHIC VALIDATION ==========\n",
    "\n",
    "# Cities within Fraser Health Authority jurisdiction\n",
    "# Fraser Health cities\n",
    "FRASER_HEALTH_CITIES = ['Surrey', 'Burnaby', 'New Westminster', 'Coquitlam']\n",
    "\n",
    "# Distance threshold to flag unrealistic patient travel\n",
    "# Distance threshold for \"teleporting\" patients (km)\n",
    "# Patients traveling >100km for routine care may indicate data quality issues\n",
    "MAX_PATIENT_PROVIDER_DISTANCE_KM = 100  # Flag if > 100km\n",
    "\n",
    "\n# ========== TEST TRACKING ==========\n",
    "# Validation results storage\n",
    "# Central repository for all validation test results\n",
    "validation_results = {\n",
    "    'timestamp': datetime.now().isoformat(),\n",
    "    'tests': [],\n",
    "    'passed': 0,\n",
    "    'failed': 0,\n",
    "    'warnings': 0\n",
    "}\n",
    "\n",
    "def log_test(category, test_name, status, message, details=None):\n",
    "    \"\"\"Log a test result\"\"\"\n",
    "    result = {\n",
    "        'category': category,\n",
    "        'test': test_name,\n",
    "        'status': status,  # PASS, FAIL, WARN\n",
    "        'message': message,\n",
    "        'details': details or {}\n",
    "    }\n",
    "    validation_results['tests'].append(result)\n",
    "    \n",
    "    if status == 'PASS':\n",
    "        validation_results['passed'] += 1\n",
    "        icon = '✓'\n",
    "    elif status == 'FAIL':\n",
    "        validation_results['failed'] += 1\n",
    "        icon = '✗'\n",
    "    else:  # WARN\n",
    "        validation_results['warnings'] += 1\n",
    "        icon = '⚠'\n",
    "    \n",
    "    print(f\"{icon} [{category}] {test_name}: {message}\")\n",
    "    return result\n",
    "\n",
    "print(\"Configuration loaded:\")\n",
    "print(f\"  CSV Directory: {CSV_DIR}\")\n",
    "print(f\"  FHIR Directory: {FHIR_DIR}\")\n",
    "print(f\"  BC Median Age (2021 Census): {BC_MEDIAN_AGE_2021} years\")\n",
    "print(f\"  Fraser Health Cities: {', '.join(FRASER_HEALTH_CITIES)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0.4 Load Generated Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data_file(filename, required=True):\n",
    "    \"\"\"Load a CSV file from the output directory\"\"\"\n",
    "    \"\"\"Load a CSV file from the output directory\n    \n    Args:\n        filename: Name of the CSV file to load\n        required: If True, logs FAIL if file not found; if False, logs WARN\n    \n    Returns:\n        DataFrame if successful, None if file not found or error occurred\n    \"\"\"\n",
    "    filepath = CSV_DIR / filename\n",
    "    if not filepath.exists():\n",
    "        # File doesn't exist - log appropriate message\n",
    "        msg = f\"File not found: {filepath}\"\n",
    "        if required:\n",
    "            log_test(\"Setup\", f\"Load {filename}\", \"FAIL\", msg)\n",
    "            return None\n",
    "        else:\n",
    "            log_test(\"Setup\", f\"Load {filename}\", \"WARN\", f\"{msg} (optional)\")\n",
    "            return None\n",
    "    \n",
    "        # Try to read the CSV file\n",
    "    try:\n",
    "        df = pd.read_csv(filepath)\n",
    "        log_test(\"Setup\", f\"Load {filename}\", \"PASS\", f\"Loaded {len(df)} rows\")\n",
    "        return df\n",
    "    except Exception as e:\n",
    "        # Handle any pandas read errors\n",
    "        log_test(\"Setup\", f\"Load {filename}\", \"FAIL\", f\"Error loading: {e}\")\n",
    "        return None\n",
    "\n",
    "print(\"Loading generated data files...\")\n",
    "\n# ========== LOAD CORE DATASETS ==========\n",
    "print()\n",
    "# These files are generated by fraser_health_onboarding.ipynb\n",
    "\n",
    "# Load required files\n",
    "\n# Load primary patient and encounter data (required for all tests)\n",
    "patients_df = load_data_file(\"patients.csv\", required=True)\n",
    "encounters_df = load_data_file(\"encounters.csv\", required=True)\n",
    "organizations_df = load_data_file(\"organizations.csv\", required=False)\n",
    "conditions_df = load_data_file(\"conditions.csv\", required=False)\n",
    "\n",
    "\n# ========== LOAD CONFIGURATION FILES ==========\n",
    "# Load config files if available\n",
    "# These are the filtered CSV files created during onboarding\n",
    "print(\"\\nLoading configuration files...\")\n",
    "# Used to validate that generated data matches configuration\n",
    "demographics_config = None\n",
    "hospitals_config = None\n",
    "\n",
    "if CONFIG_DIR.exists():\n",
    "    demographics_path = CONFIG_DIR / \"demographics_ca.csv\"\n",
    "    hospitals_path = CONFIG_DIR / \"hospitals_ca.csv\"\n",
    "    \n",
    "    if demographics_path.exists():\n",
    "        try:\n",
    "            demographics_config = pd.read_csv(demographics_path)\n",
    "            log_test(\"Setup\", \"Load demographics_ca.csv\", \"PASS\", f\"Loaded {len(demographics_config)} rows\")\n",
    "        except Exception as e:\n",
    "            log_test(\"Setup\", \"Load demographics_ca.csv\", \"WARN\", f\"Error: {e}\")\n",
    "    \n",
    "    if hospitals_path.exists():\n",
    "        try:\n",
    "            hospitals_config = pd.read_csv(hospitals_path)\n",
    "            log_test(\"Setup\", \"Load hospitals_ca.csv\", \"PASS\", f\"Loaded {len(hospitals_config)} rows\")\n",
    "        except Exception as e:\n",
    "            log_test(\"Setup\", \"Load hospitals_ca.csv\", \"WARN\", f\"Error: {e}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(f\"Data Loading Summary: {validation_results['passed']} passed, {validation_results['failed']} failed, {validation_results['warnings']} warnings\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 1: Statistical Demographic Parity Tests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Age Distribution Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if patients_df is not None:\n",
    "    print(\"=\"*70)\n",
    "    print(\"TEST 1.1: AGE DISTRIBUTION vs BC 2021 CENSUS\")\n",
    "    print(\"=\"*70)\n",
    "    \n    # ========== CALCULATE AGE STATISTICS ==========\n",
    "    print()\n",
    "    # Extract birth year from BIRTHDATE column and calculate current age\n",
    "    \n",
    "    # Calculate patient ages\n",
    "    if 'BIRTHDATE' in patients_df.columns:\n",
    "        patients_df['BIRTHDATE'] = pd.to_datetime(patients_df['BIRTHDATE'])\n",
    "    \n    # ========== COMPARE TO CENSUS BASELINE ==========\n",
    "        reference_date = pd.Timestamp.now()\n",
    "    # Check if synthetic data median age is within tolerance of BC 2021 Census\n",
    "        patients_df['AGE'] = (reference_date - patients_df['BIRTHDATE']).dt.days / 365.25\n",
    "        \n",
    "        median_age = patients_df['AGE'].median()\n",
    "        mean_age = patients_df['AGE'].mean()\n",
    "        \n",
    "        print(f\"Generated Data Statistics:\")\n",
    "    \n    # ========== VISUALIZE DISTRIBUTION ==========\n",
    "        print(f\"  Median Age: {median_age:.1f} years\")\n",
    "    # Create histogram to show age distribution and identify outliers\n",
    "        print(f\"  Mean Age: {mean_age:.1f} years\")\n",
    "        print(f\"  Age Range: {patients_df['AGE'].min():.1f} - {patients_df['AGE'].max():.1f} years\")\n",
    "        print()\n",
    "        print(f\"BC 2021 Census Baseline:\")\n",
    "        print(f\"  Median Age: {BC_MEDIAN_AGE_2021} years\")\n",
    "        print(f\"  Tolerance: ±{BC_AGE_TOLERANCE*100:.0f}%\")\n",
    "        print()\n",
    "        \n",
    "        # Test: Median age deviation\n",
    "        deviation = abs(median_age - BC_MEDIAN_AGE_2021) / BC_MEDIAN_AGE_2021\n",
    "        if deviation <= BC_AGE_TOLERANCE:\n",
    "            log_test(\"Demographics\", \"Age Distribution - Median\", \"PASS\",\n",
    "                    f\"Median age {median_age:.1f} is within {BC_AGE_TOLERANCE*100:.0f}% of BC baseline ({BC_MEDIAN_AGE_2021})\",\n",
    "                    {'median_age': median_age, 'bc_baseline': BC_MEDIAN_AGE_2021, 'deviation_pct': deviation*100})\n",
    "        else:\n",
    "            log_test(\"Demographics\", \"Age Distribution - Median\", \"FAIL\",\n",
    "                    f\"Median age {median_age:.1f} deviates by {deviation*100:.1f}% from BC baseline (>{BC_AGE_TOLERANCE*100:.0f}%)\",\n",
    "                    {'median_age': median_age, 'bc_baseline': BC_MEDIAN_AGE_2021, 'deviation_pct': deviation*100})\n",
    "        \n",
    "        # Plot age distribution\n",
    "        plt.figure(figsize=(12, 5))\n",
    "        \n",
    "        plt.subplot(1, 2, 1)\n",
    "        plt.hist(patients_df['AGE'], bins=20, edgecolor='black', alpha=0.7)\n",
    "        plt.axvline(median_age, color='red', linestyle='--', label=f'Median: {median_age:.1f}')\n",
    "        plt.axvline(BC_MEDIAN_AGE_2021, color='green', linestyle='--', label=f'BC 2021: {BC_MEDIAN_AGE_2021}')\n",
    "        plt.xlabel('Age (years)')\n",
    "        plt.ylabel('Frequency')\n",
    "        plt.title('Age Distribution of Generated Patients')\n",
    "        plt.legend()\n",
    "        plt.grid(True, alpha=0.3)\n",
    "        \n",
    "        plt.subplot(1, 2, 2)\n",
    "        age_groups = pd.cut(patients_df['AGE'], bins=[0, 18, 30, 45, 60, 75, 120], \n",
    "                           labels=['0-17', '18-29', '30-44', '45-59', '60-74', '75+'])\n",
    "        age_group_counts = age_groups.value_counts().sort_index()\n",
    "        age_group_counts.plot(kind='bar', color='steelblue', edgecolor='black')\n",
    "        plt.xlabel('Age Group')\n",
    "        plt.ylabel('Count')\n",
    "        plt.title('Age Group Distribution')\n",
    "        plt.xticks(rotation=45)\n",
    "        plt.grid(True, alpha=0.3, axis='y')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "    else:\n",
    "        log_test(\"Demographics\", \"Age Distribution\", \"FAIL\", \"BIRTHDATE column not found\")\n",
    "else:\n",
    "    log_test(\"Demographics\", \"Age Distribution\", \"FAIL\", \"Patient data not loaded\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Ethnicity Distribution Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if patients_df is not None:\n",
    "    print()\n",
    "    print(\"=\"*70)\n",
    "    print(\"TEST 1.2: ETHNICITY DISTRIBUTION vs FRASER HEALTH DEMOGRAPHICS\")\n",
    "    \n    # ========== ANALYZE ETHNICITY REPRESENTATION ==========\n",
    "    print(\"=\"*70)\n",
    "    # Fraser Health serves diverse populations, particularly South Asian and East Asian communities\n",
    "    print()\n",
    "    # This test verifies that synthetic data reflects this demographic reality\n",
    "    \n",
    "    # Check for ethnicity/race columns\n",
    "    ethnicity_col = None\n",
    "    for col in ['ETHNICITY', 'RACE', 'ethnicity', 'race']:\n",
    "        if col in patients_df.columns:\n",
    "            ethnicity_col = col\n",
    "            break\n",
    "    \n",
    "    if ethnicity_col:\n",
    "        ethnicity_dist = patients_df[ethnicity_col].value_counts()\n",
    "        total = len(patients_df)\n",
    "        \n",
    "    \n    # ========== CHECK FOR EXPECTED ETHNICITIES ==========\n",
    "        print(\"Generated Ethnicity Distribution:\")\n",
    "    # Surrey and surrounding Fraser Health cities have significant South Asian and East Asian populations\n",
    "        for ethnicity, count in ethnicity_dist.items():\n",
    "            pct = (count / total) * 100\n",
    "            print(f\"  {ethnicity}: {count} ({pct:.1f}%)\")\n",
    "        print()\n",
    "        \n",
    "        # Check for South Asian and East Asian representation\n",
    "        # Fraser Health has high South Asian (especially Surrey) and East Asian populations\n",
    "        ethnicities_str = ' '.join(ethnicity_dist.index.str.lower())\n",
    "        \n",
    "        has_south_asian = any(term in ethnicities_str for term in ['asian', 'indian', 'south'])\n",
    "        has_east_asian = any(term in ethnicities_str for term in ['asian', 'chinese', 'east'])\n",
    "        \n",
    "        if has_south_asian or has_east_asian:\n",
    "            log_test(\"Demographics\", \"Ethnicity Distribution\", \"PASS\",\n",
    "                    \"Dataset includes Asian ethnic groups consistent with Fraser Health demographics\",\n",
    "                    {'ethnicities': ethnicity_dist.to_dict()})\n",
    "        else:\n",
    "            log_test(\"Demographics\", \"Ethnicity Distribution\", \"WARN\",\n",
    "                    \"Asian ethnic groups may be underrepresented for Fraser Health region\",\n",
    "                    {'ethnicities': ethnicity_dist.to_dict()})\n",
    "        \n",
    "        # Plot ethnicity distribution\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        ethnicity_dist.plot(kind='bar', color='coral', edgecolor='black')\n",
    "        plt.xlabel('Ethnicity')\n",
    "        plt.ylabel('Count')\n",
    "        plt.title('Ethnicity Distribution of Generated Patients')\n",
    "        plt.xticks(rotation=45, ha='right')\n",
    "        plt.grid(True, alpha=0.3, axis='y')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "    else:\n",
    "        log_test(\"Demographics\", \"Ethnicity Distribution\", \"WARN\", \n",
    "                \"No ethnicity/race column found in patient data\")\n",
    "        \n",
    "    # Compare with demographics config if available\n",
    "    if demographics_config is not None:\n",
    "        print(\"Demographics configuration loaded - can be used for detailed comparison\")\n",
    "        if 'RACE' in demographics_config.columns or 'ETHNICITY' in demographics_config.columns:\n",
    "            print(\"Reference ethnicity data available in config\")\n",
    "else:\n",
    "    log_test(\"Demographics\", \"Ethnicity Distribution\", \"FAIL\", \"Patient data not loaded\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 2: Geographic Integrity & Referral Routing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Fraser Health Boundary Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if patients_df is not None:\n",
    "    print(\"=\"*70)\n",
    "    print(\"TEST 2.1: FRASER HEALTH BOUNDARY CHECK\")\n",
    "    print(\"=\"*70)\n",
    "    \n    # ========== VERIFY GEOGRAPHIC BOUNDARIES ==========\n",
    "    print()\n",
    "    # All patients must reside in one of the four target Fraser Health cities\n",
    "    \n",
    "    # This ensures we're generating data for the correct health authority region\n",
    "    # Check patient cities\n",
    "    city_col = None\n",
    "    for col in ['CITY', 'city', 'City']:\n",
    "        if col in patients_df.columns:\n",
    "            city_col = col\n",
    "            break\n",
    "    \n",
    "    if city_col:\n",
    "        patient_cities = patients_df[city_col].value_counts()\n",
    "        print(\"Patient Cities Distribution:\")\n",
    "        for city, count in patient_cities.items():\n",
    "    \n    # ========== IDENTIFY INVALID LOCATIONS ==========\n",
    "            in_fraser = \"✓\" if city in FRASER_HEALTH_CITIES else \"✗\"\n",
    "    # Any patient outside Fraser Health boundaries indicates a configuration error\n",
    "            print(f\"  {in_fraser} {city}: {count}\")\n",
    "        print()\n",
    "        \n",
    "        # Test: All patients should be in Fraser Health cities\n",
    "        patients_in_fraser = patients_df[city_col].isin(FRASER_HEALTH_CITIES).sum()\n",
    "        total_patients = len(patients_df)\n",
    "        pct_in_fraser = (patients_in_fraser / total_patients) * 100\n",
    "        \n",
    "        if pct_in_fraser == 100:\n",
    "            log_test(\"Geography\", \"Fraser Health Boundary\", \"PASS\",\n",
    "                    f\"All {total_patients} patients are in Fraser Health cities\",\n",
    "                    {'cities': patient_cities.to_dict()})\n",
    "        elif pct_in_fraser >= 90:\n",
    "            log_test(\"Geography\", \"Fraser Health Boundary\", \"WARN\",\n",
    "                    f\"{pct_in_fraser:.1f}% of patients in Fraser Health cities (not 100%)\",\n",
    "                    {'cities': patient_cities.to_dict(), 'pct_in_fraser': pct_in_fraser})\n",
    "        else:\n",
    "            log_test(\"Geography\", \"Fraser Health Boundary\", \"FAIL\",\n",
    "                    f\"Only {pct_in_fraser:.1f}% of patients in Fraser Health cities\",\n",
    "                    {'cities': patient_cities.to_dict(), 'pct_in_fraser': pct_in_fraser})\n",
    "    else:\n",
    "        log_test(\"Geography\", \"Fraser Health Boundary\", \"FAIL\", \"No city column found in patient data\")\n",
    "else:\n",
    "    log_test(\"Geography\", \"Fraser Health Boundary\", \"FAIL\", \"Patient data not loaded\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Provider-Patient Location Matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if patients_df is not None and encounters_df is not None and organizations_df is not None:\n",
    "    print()\n",
    "    print(\"=\"*70)\n",
    "    print(\"TEST 2.2: PROVIDER-PATIENT LOCATION MATCHING\")\n",
    "    \n    # ========== VALIDATE PROVIDER LOCATIONS ==========\n",
    "    print(\"=\"*70)\n",
    "    # Ensure healthcare providers (hospitals, clinics) are within Fraser Health boundaries\n",
    "    print()\n",
    "    # This prevents patients from being assigned to providers outside their health authority\n",
    "    \n",
    "    # Merge encounters with organizations to get provider locations\n",
    "    encounters_with_org = encounters_df.merge(\n",
    "        organizations_df[['Id', 'NAME', 'CITY', 'STATE'] if 'STATE' in organizations_df.columns else ['Id', 'NAME', 'CITY']],\n",
    "        left_on='ORGANIZATION' if 'ORGANIZATION' in encounters_df.columns else 'PROVIDER',\n",
    "        right_on='Id',\n",
    "        how='left',\n",
    "        suffixes=('_enc', '_org')\n",
    "    )\n",
    "    \n",
    "    # Get patient cities\n",
    "    patient_city_col = None\n",
    "    for col in ['CITY', 'city']:\n",
    "        if col in patients_df.columns:\n",
    "            patient_city_col = col\n",
    "            break\n",
    "    \n",
    "    if patient_city_col:\n",
    "        # Merge with patients to get patient city\n",
    "        full_data = encounters_with_org.merge(\n",
    "            patients_df[['Id', patient_city_col]],\n",
    "            left_on='PATIENT',\n",
    "            right_on='Id',\n",
    "            how='left',\n",
    "            suffixes=('', '_patient')\n",
    "        )\n",
    "        \n",
    "        # Check if provider city matches patient city or is in Fraser Health\n",
    "        if 'CITY_org' in full_data.columns:\n",
    "            provider_cities = full_data['CITY_org'].value_counts()\n",
    "            print(\"Provider Cities:\")\n",
    "            for city, count in provider_cities.head(10).items():\n",
    "                if pd.notna(city):\n",
    "                    in_fraser = \"✓\" if city in FRASER_HEALTH_CITIES else \"✗\"\n",
    "                    print(f\"  {in_fraser} {city}: {count} encounters\")\n",
    "            print()\n",
    "            \n",
    "            # Test: Providers should be in Fraser Health\n",
    "            providers_in_fraser = full_data['CITY_org'].isin(FRASER_HEALTH_CITIES).sum()\n",
    "            total_encounters = len(full_data)\n",
    "            pct_in_fraser = (providers_in_fraser / total_encounters) * 100 if total_encounters > 0 else 0\n",
    "            \n",
    "            if pct_in_fraser >= 90:\n",
    "                log_test(\"Geography\", \"Provider Location\", \"PASS\",\n",
    "                        f\"{pct_in_fraser:.1f}% of encounters are with Fraser Health providers\",\n",
    "                        {'pct_in_fraser': pct_in_fraser})\n",
    "            elif pct_in_fraser >= 70:\n",
    "                log_test(\"Geography\", \"Provider Location\", \"WARN\",\n",
    "                        f\"Only {pct_in_fraser:.1f}% of encounters with Fraser Health providers\",\n",
    "                        {'pct_in_fraser': pct_in_fraser})\n",
    "            else:\n",
    "                log_test(\"Geography\", \"Provider Location\", \"FAIL\",\n",
    "                        f\"Only {pct_in_fraser:.1f}% of encounters with Fraser Health providers\",\n",
    "                        {'pct_in_fraser': pct_in_fraser})\n",
    "        else:\n",
    "            log_test(\"Geography\", \"Provider Location\", \"WARN\", \n",
    "                    \"Provider city information not available in merged data\")\n",
    "    else:\n",
    "        log_test(\"Geography\", \"Provider Location\", \"WARN\", \"Patient city column not found\")\n",
    "        \n",
    "elif organizations_df is None:\n",
    "    log_test(\"Geography\", \"Provider Location\", \"WARN\", \"Organizations data not loaded\")\n",
    "else:\n",
    "    log_test(\"Geography\", \"Provider Location\", \"FAIL\", \"Required data not loaded\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Haversine Distance Check (Teleporting Patients)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if patients_df is not None and organizations_df is not None and haversine_available:\n",
    "    print()\n",
    "    print(\"=\"*70)\n",
    "    print(\"TEST 2.3: PATIENT-PROVIDER DISTANCE CHECK\")\n",
    "    \n    # ========== CALCULATE PATIENT-PROVIDER DISTANCES ==========\n",
    "    print(\"=\"*70)\n",
    "    # Use haversine formula to compute great-circle distance between patient home and provider\n",
    "    print()\n",
    "    # Identifies 'teleporting' patients who travel unrealistic distances for care\n",
    "    \n",
    "    # Check for coordinate columns\n",
    "    patient_has_coords = 'LAT' in patients_df.columns and 'LON' in patients_df.columns\n",
    "    org_has_coords = 'LAT' in organizations_df.columns and 'LON' in organizations_df.columns\n",
    "    \n",
    "    if patient_has_coords and org_has_coords and encounters_df is not None:\n",
    "        # Sample encounters for distance calculation (to avoid performance issues)\n",
    "        sample_size = min(100, len(encounters_df))\n",
    "        sample_encounters = encounters_df.sample(n=sample_size, random_state=42) if len(encounters_df) > sample_size else encounters_df\n",
    "        \n",
    "    \n    # ========== DETECT OUTLIERS ==========\n",
    "        print(f\"Analyzing {len(sample_encounters)} encounters for distance validation...\")\n",
    "    # Flag any patient traveling more than 100km for routine healthcare\n",
    "        print()\n",
    "    # In Fraser Health region, most patients should be within 50km of their provider\n",
    "        \n",
    "        distances = []\n",
    "        teleporting_count = 0\n",
    "        \n",
    "        for _, enc in sample_encounters.iterrows():\n",
    "            patient_id = enc.get('PATIENT')\n",
    "            org_id = enc.get('ORGANIZATION') if 'ORGANIZATION' in enc else enc.get('PROVIDER')\n",
    "            \n",
    "            if pd.notna(patient_id) and pd.notna(org_id):\n",
    "                patient_row = patients_df[patients_df['Id'] == patient_id]\n",
    "                org_row = organizations_df[organizations_df['Id'] == org_id]\n",
    "                \n",
    "                if not patient_row.empty and not org_row.empty:\n",
    "                    patient_coords = (patient_row.iloc[0]['LAT'], patient_row.iloc[0]['LON'])\n",
    "                    org_coords = (org_row.iloc[0]['LAT'], org_row.iloc[0]['LON'])\n",
    "                    \n",
    "                    # Calculate Haversine distance\n",
    "                    distance = haversine(patient_coords, org_coords, unit=Unit.KILOMETERS)\n",
    "                    distances.append(distance)\n",
    "                    \n",
    "                    if distance > MAX_PATIENT_PROVIDER_DISTANCE_KM:\n",
    "                        teleporting_count += 1\n",
    "        \n",
    "        if distances:\n",
    "            avg_distance = np.mean(distances)\n",
    "            max_distance = np.max(distances)\n",
    "            teleporting_pct = (teleporting_count / len(distances)) * 100\n",
    "            \n",
    "            print(f\"Distance Statistics (km):\")\n",
    "            print(f\"  Average: {avg_distance:.1f} km\")\n",
    "            print(f\"  Maximum: {max_distance:.1f} km\")\n",
    "            print(f\"  Median: {np.median(distances):.1f} km\")\n",
    "            print(f\"  'Teleporting' patients (>{MAX_PATIENT_PROVIDER_DISTANCE_KM}km): {teleporting_count} ({teleporting_pct:.1f}%)\")\n",
    "            print()\n",
    "            \n",
    "            # Test: Flag if too many teleporting patients\n",
    "            if teleporting_pct == 0:\n",
    "                log_test(\"Geography\", \"Distance Check\", \"PASS\",\n",
    "                        f\"No teleporting patients detected (all within {MAX_PATIENT_PROVIDER_DISTANCE_KM}km)\",\n",
    "                        {'avg_distance_km': avg_distance, 'max_distance_km': max_distance})\n",
    "            elif teleporting_pct <= 5:\n",
    "                log_test(\"Geography\", \"Distance Check\", \"PASS\",\n",
    "                        f\"Only {teleporting_pct:.1f}% teleporting patients (<5% threshold)\",\n",
    "                        {'avg_distance_km': avg_distance, 'max_distance_km': max_distance, 'teleporting_pct': teleporting_pct})\n",
    "            elif teleporting_pct <= 10:\n",
    "                log_test(\"Geography\", \"Distance Check\", \"WARN\",\n",
    "                        f\"{teleporting_pct:.1f}% teleporting patients (>5% but <10%)\",\n",
    "                        {'avg_distance_km': avg_distance, 'max_distance_km': max_distance, 'teleporting_pct': teleporting_pct})\n",
    "            else:\n",
    "                log_test(\"Geography\", \"Distance Check\", \"FAIL\",\n",
    "                        f\"{teleporting_pct:.1f}% teleporting patients (>10% threshold)\",\n",
    "                        {'avg_distance_km': avg_distance, 'max_distance_km': max_distance, 'teleporting_pct': teleporting_pct})\n",
    "            \n",
    "            # Plot distance distribution\n",
    "            plt.figure(figsize=(10, 5))\n",
    "            plt.hist(distances, bins=20, edgecolor='black', alpha=0.7, color='skyblue')\n",
    "            plt.axvline(MAX_PATIENT_PROVIDER_DISTANCE_KM, color='red', linestyle='--', \n",
    "                       label=f'Threshold: {MAX_PATIENT_PROVIDER_DISTANCE_KM}km')\n",
    "            plt.xlabel('Distance (km)')\n",
    "            plt.ylabel('Frequency')\n",
    "            plt.title('Patient-Provider Distance Distribution')\n",
    "            plt.legend()\n",
    "            plt.grid(True, alpha=0.3)\n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "        else:\n",
    "            log_test(\"Geography\", \"Distance Check\", \"WARN\", \"No valid coordinate pairs found for distance calculation\")\n",
    "    else:\n",
    "        missing = []\n",
    "        if not patient_has_coords:\n",
    "            missing.append(\"patient coordinates\")\n",
    "        if not org_has_coords:\n",
    "            missing.append(\"organization coordinates\")\n",
    "        log_test(\"Geography\", \"Distance Check\", \"WARN\", \n",
    "                f\"Cannot perform distance check - missing: {', '.join(missing)}\")\n",
    "else:\n",
    "    if not haversine_available:\n",
    "        log_test(\"Geography\", \"Distance Check\", \"WARN\", \"Haversine library not available\")\n",
    "    else:\n",
    "        log_test(\"Geography\", \"Distance Check\", \"FAIL\", \"Required data not loaded\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 3: Clinical Timeline & FHIR R4 Compliance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Encounter Sequence Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if encounters_df is not None and patients_df is not None:\n",
    "    print(\"=\"*70)\n",
    "    print(\"TEST 3.1: CLINICAL ENCOUNTER SEQUENCE VALIDATION\")\n",
    "    print(\"=\"*70)\n",
    "    \n    # ========== VALIDATE CLINICAL TIMELINES ==========\n",
    "    print()\n",
    "    # Ensure encounters happen in logical chronological order\n",
    "    \n",
    "    # Example: inpatient stays should be preceded by ambulatory or emergency visits\n",
    "    # Check for date and encounter type columns\n",
    "    has_date = 'START' in encounters_df.columns or 'DATE' in encounters_df.columns\n",
    "    has_type = 'ENCOUNTERCLASS' in encounters_df.columns or 'CLASS' in encounters_df.columns\n",
    "    \n",
    "    if has_date and has_type:\n",
    "        date_col = 'START' if 'START' in encounters_df.columns else 'DATE'\n",
    "        type_col = 'ENCOUNTERCLASS' if 'ENCOUNTERCLASS' in encounters_df.columns else 'CLASS'\n",
    "        \n",
    "        # Convert dates\n",
    "        encounters_df[date_col] = pd.to_datetime(encounters_df[date_col], errors='coerce')\n",
    "        \n",
    "        # Sample patients for detailed analysis\n",
    "        sample_patients = patients_df['Id'].sample(n=min(10, len(patients_df)), random_state=42).tolist()\n",
    "        \n",
    "        print(f\"Analyzing encounter sequences for {len(sample_patients)} sample patients...\")\n",
    "    \n    # ========== CHECK ENCOUNTER PATTERNS ==========\n",
    "        print()\n",
    "    # Look for suspicious patterns like inpatient admission without prior encounters\n",
    "        \n",
    "        sequence_issues = []\n",
    "        valid_sequences = 0\n",
    "        \n",
    "        for patient_id in sample_patients:\n",
    "            patient_encounters = encounters_df[encounters_df['PATIENT'] == patient_id].sort_values(date_col)\n",
    "            \n",
    "            if len(patient_encounters) > 1:\n",
    "                encounter_types = patient_encounters[type_col].tolist()\n",
    "                \n",
    "                # Check for logical sequences\n",
    "                # e.g., Inpatient should typically be preceded by Emergency or Ambulatory\n",
    "                for i in range(1, len(encounter_types)):\n",
    "                    current_type = encounter_types[i]\n",
    "                    previous_type = encounter_types[i-1]\n",
    "                    \n",
    "                    # Simple validation: Inpatient typically follows Emergency/Ambulatory/Urgent\n",
    "                    if current_type in ['inpatient', 'Inpatient', 'INPATIENT']:\n",
    "                        if previous_type not in ['emergency', 'Emergency', 'EMERGENCY', \n",
    "                                                'ambulatory', 'Ambulatory', 'AMBULATORY',\n",
    "                                                'urgent', 'Urgent', 'URGENT',\n",
    "                                                'inpatient', 'Inpatient', 'INPATIENT']:\n",
    "                            sequence_issues.append({\n",
    "                                'patient_id': patient_id,\n",
    "                                'sequence': f\"{previous_type} -> {current_type}\",\n",
    "                                'issue': 'Inpatient without preceding appropriate encounter'\n",
    "                            })\n",
    "                \n",
    "                if not sequence_issues or sequence_issues[-1]['patient_id'] != patient_id:\n",
    "                    valid_sequences += 1\n",
    "        \n",
    "        print(f\"Sequence Validation Results:\")\n",
    "        print(f\"  Valid sequences: {valid_sequences}/{len(sample_patients)}\")\n",
    "        print(f\"  Issues found: {len(sequence_issues)}\")\n",
    "        \n",
    "        if sequence_issues:\n",
    "            print(f\"\\n  Sample issues:\")\n",
    "            for issue in sequence_issues[:3]:\n",
    "                print(f\"    - Patient {issue['patient_id'][:8]}...: {issue['sequence']}\")\n",
    "        print()\n",
    "        \n",
    "        # Test: Most sequences should be valid\n",
    "        valid_pct = (valid_sequences / len(sample_patients)) * 100 if sample_patients else 0\n",
    "        \n",
    "        if valid_pct >= 80:\n",
    "            log_test(\"Clinical\", \"Encounter Sequences\", \"PASS\",\n",
    "                    f\"{valid_pct:.0f}% of sampled patients have valid encounter sequences\",\n",
    "                    {'valid_count': valid_sequences, 'total_sampled': len(sample_patients)})\n",
    "        elif valid_pct >= 60:\n",
    "            log_test(\"Clinical\", \"Encounter Sequences\", \"WARN\",\n",
    "                    f\"Only {valid_pct:.0f}% of sampled patients have valid sequences\",\n",
    "                    {'valid_count': valid_sequences, 'total_sampled': len(sample_patients), 'issues': len(sequence_issues)})\n",
    "        else:\n",
    "            log_test(\"Clinical\", \"Encounter Sequences\", \"FAIL\",\n",
    "                    f\"Only {valid_pct:.0f}% of sampled patients have valid sequences\",\n",
    "                    {'valid_count': valid_sequences, 'total_sampled': len(sample_patients), 'issues': len(sequence_issues)})\n",
    "        \n",
    "        # Show encounter type distribution\n",
    "        encounter_type_dist = encounters_df[type_col].value_counts()\n",
    "        print(\"Encounter Type Distribution:\")\n",
    "        for enc_type, count in encounter_type_dist.items():\n",
    "            print(f\"  {enc_type}: {count}\")\n",
    "            \n",
    "    else:\n",
    "        missing = []\n",
    "        if not has_date:\n",
    "            missing.append(\"date column\")\n",
    "        if not has_type:\n",
    "            missing.append(\"encounter type column\")\n",
    "        log_test(\"Clinical\", \"Encounter Sequences\", \"WARN\", \n",
    "                f\"Cannot validate sequences - missing: {', '.join(missing)}\")\n",
    "else:\n",
    "    log_test(\"Clinical\", \"Encounter Sequences\", \"FAIL\", \"Required data not loaded\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 FHIR R4 Bundle Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if fhir_available:\n",
    "    print()\n",
    "    print(\"=\"*70)\n",
    "    print(\"TEST 3.2: FHIR R4 BUNDLE VALIDATION\")\n",
    "    \n    # ========== VALIDATE FHIR CONFORMANCE ==========\n",
    "    print(\"=\"*70)\n",
    "    # FHIR R4 is the international standard for healthcare data exchange\n",
    "    print()\n",
    "    # Each patient should have a valid FHIR Bundle containing all their health records\n",
    "    \n",
    "    if FHIR_DIR.exists():\n",
    "        fhir_files = list(FHIR_DIR.glob(\"*.json\"))\n",
    "        \n",
    "        if fhir_files:\n",
    "            print(f\"Found {len(fhir_files)} FHIR JSON files\")\n",
    "            print()\n",
    "            \n",
    "            # Sample and validate FHIR files\n",
    "            sample_size = min(10, len(fhir_files))\n",
    "    \n    # ========== VERIFY BC-SPECIFIC REQUIREMENTS ==========\n",
    "            sample_files = fhir_files[:sample_size]\n",
    "    # All address.state values must be 'BC' for British Columbia\n",
    "            \n",
    "    # This ensures data is properly tagged for provincial health systems\n",
    "            valid_bundles = 0\n",
    "            bc_address_count = 0\n",
    "            validation_errors = []\n",
    "            \n",
    "            for fhir_file in sample_files:\n",
    "                try:\n",
    "                    with open(fhir_file, 'r') as f:\n",
    "                        fhir_data = json.load(f)\n",
    "                    \n",
    "                    # Try to parse as FHIR Bundle\n",
    "                    try:\n",
    "                        bundle = Bundle.parse_obj(fhir_data)\n",
    "                        valid_bundles += 1\n",
    "                        \n",
    "                        # Check for BC addresses\n",
    "                        if 'entry' in fhir_data:\n",
    "                            for entry in fhir_data['entry']:\n",
    "                                if 'resource' in entry:\n",
    "                                    resource = entry['resource']\n",
    "                                    if resource.get('resourceType') == 'Patient':\n",
    "                                        if 'address' in resource:\n",
    "                                            for addr in resource['address']:\n",
    "                                                if addr.get('state') == 'BC' or addr.get('state') == 'British Columbia':\n",
    "                                                    bc_address_count += 1\n",
    "                                                    break\n",
    "                    except Exception as e:\n",
    "                        validation_errors.append({\n",
    "                            'file': fhir_file.name,\n",
    "                            'error': str(e)\n",
    "                        })\n",
    "                        \n",
    "                except Exception as e:\n",
    "                    validation_errors.append({\n",
    "                        'file': fhir_file.name,\n",
    "                        'error': f\"Failed to load: {str(e)}\"\n",
    "                    })\n",
    "            \n",
    "            print(f\"FHIR Validation Results:\")\n",
    "            print(f\"  Valid R4 Bundles: {valid_bundles}/{sample_size}\")\n",
    "            print(f\"  Files with BC addresses: {bc_address_count}\")\n",
    "            print(f\"  Validation errors: {len(validation_errors)}\")\n",
    "            \n",
    "            if validation_errors:\n",
    "                print(f\"\\n  Sample errors:\")\n",
    "                for err in validation_errors[:3]:\n",
    "                    print(f\"    - {err['file']}: {err['error'][:80]}\")\n",
    "            print()\n",
    "            \n",
    "            # Test: All sampled files should be valid\n",
    "            if valid_bundles == sample_size:\n",
    "                log_test(\"FHIR\", \"R4 Bundle Validation\", \"PASS\",\n",
    "                        f\"All {sample_size} sampled FHIR files are valid R4 bundles\",\n",
    "                        {'valid_count': valid_bundles, 'total_sampled': sample_size})\n",
    "            elif valid_bundles >= sample_size * 0.8:\n",
    "                log_test(\"FHIR\", \"R4 Bundle Validation\", \"WARN\",\n",
    "                        f\"{valid_bundles}/{sample_size} sampled files are valid R4 bundles\",\n",
    "                        {'valid_count': valid_bundles, 'total_sampled': sample_size, 'errors': len(validation_errors)})\n",
    "            else:\n",
    "                log_test(\"FHIR\", \"R4 Bundle Validation\", \"FAIL\",\n",
    "                        f\"Only {valid_bundles}/{sample_size} sampled files are valid R4 bundles\",\n",
    "                        {'valid_count': valid_bundles, 'total_sampled': sample_size, 'errors': len(validation_errors)})\n",
    "            \n",
    "            # Test BC addresses\n",
    "            if bc_address_count > 0:\n",
    "                log_test(\"FHIR\", \"BC Address Check\", \"PASS\",\n",
    "                        f\"Found {bc_address_count} resources with BC addresses\",\n",
    "                        {'bc_address_count': bc_address_count})\n",
    "            else:\n",
    "                log_test(\"FHIR\", \"BC Address Check\", \"WARN\",\n",
    "                        \"No BC addresses found in sampled FHIR files\",\n",
    "                        {'bc_address_count': 0})\n",
    "        else:\n",
    "            log_test(\"FHIR\", \"R4 Bundle Validation\", \"WARN\", \n",
    "                    f\"No FHIR JSON files found in {FHIR_DIR}\")\n",
    "    else:\n",
    "        log_test(\"FHIR\", \"R4 Bundle Validation\", \"WARN\", \n",
    "                f\"FHIR directory not found: {FHIR_DIR}\")\n",
    "else:\n",
    "    log_test(\"FHIR\", \"R4 Bundle Validation\", \"WARN\", \n",
    "            \"fhir.resources library not available - FHIR validation skipped\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 4: Fraser Health Specific Stress Test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Top Conditions Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if conditions_df is not None:\n",
    "    print(\"=\"*70)\n",
    "    print(\"TEST 4.1: TOP CONDITIONS ANALYSIS\")\n",
    "    print(\"=\"*70)\n",
    "    \n    # ========== ANALYZE CONDITION PREVALENCE ==========\n",
    "    print()\n",
    "    # Identify most common diagnoses in synthetic population\n",
    "    \n",
    "    # Should match expected chronic disease patterns in Fraser Health region\n",
    "    # Check for required columns\n",
    "    has_code = 'CODE' in conditions_df.columns or 'SNOMED_CODE' in conditions_df.columns\n",
    "    has_description = 'DESCRIPTION' in conditions_df.columns\n",
    "    \n",
    "    if has_code:\n",
    "        code_col = 'CODE' if 'CODE' in conditions_df.columns else 'SNOMED_CODE'\n",
    "        \n",
    "        # Get top conditions\n",
    "        top_conditions = conditions_df[code_col].value_counts().head(10)\n",
    "        \n",
    "        print(\"Top 10 Conditions (by SNOMED code):\")\n",
    "        for i, (code, count) in enumerate(top_conditions.items(), 1):\n",
    "            desc = \"\"\n",
    "            if has_description:\n",
    "                desc_row = conditions_df[conditions_df[code_col] == code][['DESCRIPTION']].iloc[0]\n",
    "                desc = f\" - {desc_row['DESCRIPTION']}\"\n",
    "            print(f\"  {i}. Code {code}: {count} occurrences{desc}\")\n",
    "        print()\n",
    "        \n",
    "        # Check for expected common conditions in Fraser Health\n",
    "        # Essential Hypertension is typically one of the most common\n",
    "        condition_descriptions = []\n",
    "        if has_description:\n",
    "            condition_descriptions = conditions_df['DESCRIPTION'].str.lower().unique()\n",
    "        \n",
    "        has_hypertension = any('hypertension' in desc for desc in condition_descriptions)\n",
    "        has_diabetes = any('diabetes' in desc for desc in condition_descriptions)\n",
    "        \n",
    "        print(\"Common Chronic Conditions Check:\")\n",
    "        print(f\"  Hypertension: {'✓ Found' if has_hypertension else '✗ Not found'}\")\n",
    "        print(f\"  Diabetes: {'✓ Found' if has_diabetes else '✗ Not found'}\")\n",
    "        print()\n",
    "        \n",
    "        if has_hypertension or has_diabetes:\n",
    "            log_test(\"Conditions\", \"Common Conditions\", \"PASS\",\n",
    "                    \"Dataset includes expected common chronic conditions\",\n",
    "                    {'top_10_codes': top_conditions.to_dict()})\n",
    "        else:\n",
    "            log_test(\"Conditions\", \"Common Conditions\", \"WARN\",\n",
    "                    \"Expected chronic conditions (hypertension, diabetes) may be missing\",\n",
    "                    {'top_10_codes': top_conditions.to_dict()})\n",
    "        \n",
    "        # Store for seed stability test\n",
    "        globals()['baseline_top_conditions'] = top_conditions\n",
    "        \n",
    "    else:\n",
    "        log_test(\"Conditions\", \"Top Conditions\", \"WARN\", \"SNOMED code column not found in conditions data\")\n",
    "else:\n",
    "    log_test(\"Conditions\", \"Top Conditions\", \"WARN\", \"Conditions data not loaded - cannot analyze\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Multi-Seed Consistency Test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** This test requires running the simulation multiple times with different seeds. ",
    "For this validation notebook, we document the approach. To actually perform multi-seed testing:",
    "",
    "1. Run `fraser_health_onboarding.ipynb` with different `RANDOM_SEED` values (e.g., 12345, 12346, 12347, 12348, 12349)",
    "2. Save outputs to different directories (e.g., `output_seed_12345/`, `output_seed_12346/`, etc.)",
    "3. Load and compare results from each run",
    "",
    "Below is a template for seed stability testing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*70)\n",
    "print(\"TEST 4.2: MULTI-SEED CONSISTENCY (Template)\")\n",
    "print(\"=\"*70)\n",
    "print()\n",
    "# ========== REPRODUCIBILITY TESTING ==========\n",
    "\n",
    "# This section provides a template for multi-seed validation\n",
    "print(\"Multi-Seed Testing Approach:\")\n",
    "# Running with different random seeds ensures data generation is stable and consistent\n",
    "print()\n",
    "print(\"To test seed stability:\")\n",
    "print(\"  1. Run simulations with seeds: 12345, 12346, 12347, 12348, 12349\")\n",
    "print(\"  2. For each run, extract Top 10 conditions\")\n",
    "print(\"  3. Compare consistency across runs\")\n",
    "print()\n",
    "print(\"Expected behavior:\")\n",
    "print(\"  - Top conditions should be similar across runs\")\n",
    "print(\"  - If 'Essential Hypertension' is #1 in one run, it should be in top 5 in others\")\n",
    "print(\"  - Major deviations indicate seed instability\")\n",
    "print()\n",
    "\n",
    "# Template code for multi-seed comparison\n",
    "seed_comparison_template = '''\n",
    "# Example multi-seed comparison code:\n",
    "\n",
    "seeds = [12345, 12346, 12347, 12348, 12349]\n",
    "top_conditions_by_seed = {}\n",
    "\n",
    "for seed in seeds:\n",
    "    # Load conditions from output directory for this seed\n",
    "    conditions_file = f\"synthea/output_seed_{seed}/csv/conditions.csv\"\n",
    "    if os.path.exists(conditions_file):\n",
    "        seed_conditions = pd.read_csv(conditions_file)\n",
    "        top_10 = seed_conditions['CODE'].value_counts().head(10)\n",
    "        top_conditions_by_seed[seed] = top_10\n",
    "        \n",
    "# Compare consistency\n",
    "if len(top_conditions_by_seed) == len(seeds):\n",
    "    # Check if top condition is consistent\n",
    "    top_codes = [list(tops.index)[0] for tops in top_conditions_by_seed.values()]\n",
    "    consistency = len(set(top_codes)) / len(top_codes)\n",
    "    \n",
    "    if consistency < 0.3:  # Less than 30% variation\n",
    "        print(\"✓ PASS: Top conditions are consistent across seeds\")\n",
    "    else:\n",
    "        print(\"✗ FAIL: High variation in top conditions across seeds\")\n",
    "'''\n",
    "\n",
    "print(\"Template code for multi-seed testing:\")\n",
    "print(seed_comparison_template)\n",
    "\n",
    "log_test(\"Stress Test\", \"Multi-Seed Consistency\", \"WARN\",\n",
    "        \"Multi-seed testing requires manual execution with different seed values\",\n",
    "        {'note': 'Run simulations with 5 different seeds and compare results'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 5: Validation Report Generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1 Generate Summary Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\")\n",
    "print(\"=\"*70)\n",
    "print(\"FRASER HEALTH SYNTHETIC DATA - VALIDATION SUMMARY REPORT\")\n",
    "print(\"=\"*70)\n",
    "# ========== VALIDATION SUMMARY ==========\n",
    "print()\n",
    "# Aggregate all test results and generate final pass/fail counts\n",
    "\n",
    "# Overall statistics\n",
    "total_tests = len(validation_results['tests'])\n",
    "passed = validation_results['passed']\n",
    "failed = validation_results['failed']\n",
    "warnings = validation_results['warnings']\n",
    "\n",
    "print(f\"Validation Timestamp: {validation_results['timestamp']}\")\n",
    "print(f\"Total Tests: {total_tests}\")\n",
    "print(f\"  ✓ Passed: {passed} ({passed/total_tests*100:.1f}%)\" if total_tests > 0 else \"  ✓ Passed: 0\")\n",
    "print(f\"  ✗ Failed: {failed} ({failed/total_tests*100:.1f}%)\" if total_tests > 0 else \"  ✗ Failed: 0\")\n",
    "print(f\"  ⚠ Warnings: {warnings} ({warnings/total_tests*100:.1f}%)\" if total_tests > 0 else \"  ⚠ Warnings: 0\")\n",
    "print()\n",
    "\n",
    "# Overall status\n",
    "if failed == 0 and warnings == 0:\n",
    "    overall_status = \"✓ EXCELLENT - All tests passed\"\n",
    "elif failed == 0:\n",
    "    overall_status = \"✓ GOOD - All tests passed with some warnings\"\n",
    "elif failed <= total_tests * 0.1:\n",
    "    overall_status = \"⚠ ACCEPTABLE - Most tests passed, minor issues detected\"\n",
    "else:\n",
    "    overall_status = \"✗ NEEDS ATTENTION - Multiple test failures\"\n",
    "\n",
    "print(f\"Overall Status: {overall_status}\")\n",
    "print()\n",
    "\n",
    "# Group results by category\n",
    "print(\"=\"*70)\n",
    "print(\"RESULTS BY CATEGORY\")\n",
    "print(\"=\"*70)\n",
    "print()\n",
    "\n",
    "categories = {}\n",
    "for test in validation_results['tests']:\n",
    "    cat = test['category']\n",
    "    if cat not in categories:\n",
    "        categories[cat] = {'passed': 0, 'failed': 0, 'warned': 0, 'tests': []}\n",
    "    \n",
    "    categories[cat]['tests'].append(test)\n",
    "    if test['status'] == 'PASS':\n",
    "        categories[cat]['passed'] += 1\n",
    "    elif test['status'] == 'FAIL':\n",
    "        categories[cat]['failed'] += 1\n",
    "    else:\n",
    "        categories[cat]['warned'] += 1\n",
    "\n",
    "for category, results in categories.items():\n",
    "    total_cat = len(results['tests'])\n",
    "    print(f\"{category}:\")\n",
    "    print(f\"  Total: {total_cat} | ✓ {results['passed']} | ✗ {results['failed']} | ⚠ {results['warned']}\")\n",
    "    \n",
    "    # Show details\n",
    "    for test in results['tests']:\n",
    "        icon = '✓' if test['status'] == 'PASS' else '✗' if test['status'] == 'FAIL' else '⚠'\n",
    "        print(f\"    {icon} {test['test']}: {test['message']}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 Create Validation DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DataFrame for easy analysis\n",
    "validation_df = pd.DataFrame(validation_results['tests'])\n",
    "# Convert validation results to DataFrame for easy analysis and export\n",
    "\n",
    "# This allows filtering, sorting, and statistical analysis of test results\n",
    "print(\"=\"*70)\n",
    "print(\"VALIDATION RESULTS TABLE\")\n",
    "print(\"=\"*70)\n",
    "print()\n",
    "\n",
    "if not validation_df.empty:\n",
    "    # Display summary table\n",
    "    summary_table = validation_df.groupby(['category', 'status']).size().unstack(fill_value=0)\n",
    "    print(summary_table)\n",
    "    print()\n",
    "    \n",
    "    # Show failed tests in detail\n",
    "    failed_tests = validation_df[validation_df['status'] == 'FAIL']\n",
    "    if not failed_tests.empty:\n",
    "        print(\"=\"*70)\n",
    "        print(\"FAILED TESTS (Requires Attention)\")\n",
    "        print(\"=\"*70)\n",
    "        print()\n",
    "        for _, test in failed_tests.iterrows():\n",
    "            print(f\"Category: {test['category']}\")\n",
    "            print(f\"Test: {test['test']}\")\n",
    "            print(f\"Message: {test['message']}\")\n",
    "            if test['details']:\n",
    "                print(f\"Details: {test['details']}\")\n",
    "            print()\n",
    "else:\n",
    "    print(\"No validation results available\")\n",
    "\n",
    "# Make the dataframe available for export\n",
    "print(\"\\nValidation DataFrame created: 'validation_df'\")\n",
    "print(\"You can export it: validation_df.to_csv('validation_report.csv', index=False)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3 Generate Markdown Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a markdown report\n",
    "markdown_report = []\n",
    "# Create human-readable Markdown report for documentation\n",
    "\n",
    "# This report can be committed to version control or shared with stakeholders\n",
    "markdown_report.append(\"# Fraser Health Synthetic Data - Validation Report\\n\")\n",
    "markdown_report.append(f\"**Generated:** {validation_results['timestamp']}\\n\\n\")\n",
    "\n",
    "markdown_report.append(\"## Executive Summary\\n\")\n",
    "markdown_report.append(f\"- **Total Tests:** {total_tests}\\n\")\n",
    "markdown_report.append(f\"- **Passed:** {passed} ({passed/total_tests*100:.1f}%)\\n\" if total_tests > 0 else \"- **Passed:** 0\\n\")\n",
    "markdown_report.append(f\"- **Failed:** {failed} ({failed/total_tests*100:.1f}%)\\n\" if total_tests > 0 else \"- **Failed:** 0\\n\")\n",
    "markdown_report.append(f\"- **Warnings:** {warnings} ({warnings/total_tests*100:.1f}%)\\n\" if total_tests > 0 else \"- **Warnings:** 0\\n\")\n",
    "markdown_report.append(f\"- **Status:** {overall_status}\\n\\n\")\n",
    "\n",
    "markdown_report.append(\"## Results by Category\\n\\n\")\n",
    "\n",
    "for category, results in categories.items():\n",
    "    markdown_report.append(f\"### {category}\\n\\n\")\n",
    "    \n",
    "    for test in results['tests']:\n",
    "        icon = '✅' if test['status'] == 'PASS' else '❌' if test['status'] == 'FAIL' else '⚠️'\n",
    "        markdown_report.append(f\"{icon} **{test['test']}:** {test['message']}\\n\")\n",
    "    \n",
    "    markdown_report.append(\"\\n\")\n",
    "\n",
    "# Add recommendations\n",
    "markdown_report.append(\"## Recommendations\\n\\n\")\n",
    "\n",
    "if failed > 0:\n",
    "    markdown_report.append(\"### Critical Issues\\n\\n\")\n",
    "    for test in validation_results['tests']:\n",
    "        if test['status'] == 'FAIL':\n",
    "            markdown_report.append(f\"- **{test['category']} - {test['test']}:** {test['message']}\\n\")\n",
    "    markdown_report.append(\"\\n\")\n",
    "\n",
    "if warnings > 0:\n",
    "    markdown_report.append(\"### Warnings\\n\\n\")\n",
    "    for test in validation_results['tests']:\n",
    "        if test['status'] == 'WARN':\n",
    "            markdown_report.append(f\"- **{test['category']} - {test['test']}:** {test['message']}\\n\")\n",
    "    markdown_report.append(\"\\n\")\n",
    "\n",
    "if failed == 0 and warnings == 0:\n",
    "    markdown_report.append(\"✅ No issues detected. The synthetic data meets all validation criteria.\\n\\n\")\n",
    "\n",
    "markdown_report.append(\"---\\n\")\n",
    "markdown_report.append(\"*Report generated by Fraser Health Validation Suite*\\n\")\n",
    "\n",
    "# Save markdown report\n",
    "report_content = ''.join(markdown_report)\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"MARKDOWN REPORT\")\n",
    "print(\"=\"*70)\n",
    "print()\n",
    "print(report_content)\n",
    "\n",
    "# Save to file\n",
    "report_path = Path(\"validation_report.md\")\n",
    "with open(report_path, 'w') as f:\n",
    "    f.write(report_content)\n",
    "\n",
    "print(f\"\\n✓ Markdown report saved to: {report_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.4 Save Validation Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save validation results as JSON\n",
    "results_path = Path(\"validation_results.json\")\n",
    "# Export validation results in multiple formats for different use cases\n",
    "\n",
    "# - JSON: Machine-readable format for automation and CI/CD pipelines\n",
    "with open(results_path, 'w') as f:\n",
    "# - CSV: Spreadsheet format for analysis in Excel or other tools\n",
    "    json.dump(validation_results, f, indent=2)\n",
    "# - Markdown: Human-readable report for documentation\n",
    "\n",
    "print(f\"✓ Validation results saved to: {results_path}\")\n",
    "\n",
    "# Save DataFrame to CSV\n",
    "if not validation_df.empty:\n",
    "    csv_path = Path(\"validation_results.csv\")\n",
    "    validation_df.to_csv(csv_path, index=False)\n",
    "    print(f\"✓ Validation DataFrame saved to: {csv_path}\")\n",
    "\n",
    "print()\n",
    "print(\"=\"*70)\n",
    "print(\"VALIDATION COMPLETE\")\n",
    "print(\"=\"*70)\n",
    "print()\n",
    "print(\"Output files generated:\")\n",
    "print(f\"  1. {results_path} - Full validation results (JSON)\")\n",
    "print(f\"  2. validation_results.csv - Validation results table\")\n",
    "print(f\"  3. validation_report.md - Human-readable report\")\n",
    "print()\n",
    "print(\"Next steps:\")\n",
    "print(\"  - Review failed tests and warnings\")\n",
    "print(\"  - Address any critical issues\")\n",
    "print(\"  - Re-run validation after fixes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This validation suite provides comprehensive testing of the Fraser Health synthetic data across four key dimensions:",
    "",
    "1. **Demographics** - Ensures age and ethnicity distributions match BC/Fraser Health characteristics",
    "2. **Geography** - Validates that patients and providers are within Fraser Health boundaries with reasonable distances",
    "3. **Clinical** - Checks encounter sequences and FHIR R4 compliance",
    "4. **Consistency** - Tests stability across multiple simulation runs",
    "",
    "**How to Use This Notebook:**",
    "",
    "1. First, run `fraser_health_onboarding.ipynb` to generate synthetic data",
    "2. Run this validation notebook to check data quality",
    "3. Review the validation report and address any failures or warnings",
    "4. For multi-seed testing, manually run simulations with different seeds and compare results",
    "",
    "**Interpreting Results:**",
    "",
    "- ✓ **PASS**: Test met all criteria",
    "- ⚠ **WARN**: Test passed but with minor concerns or missing optional data",
    "- ✗ **FAIL**: Test did not meet criteria - requires attention",
    "",
    "**Continuous Improvement:**",
    "",
    "As you make changes to the data generation process, re-run this validation suite to ensure quality is maintained."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}